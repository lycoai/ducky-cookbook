
ğŸ•˜ Daily Scrum - 9:30 AM

Participants:
	â€¢	Sarah (Product Manager)
	â€¢	Ali (Backend Engineer)
	â€¢	Tania (Frontend Engineer)
	â€¢	Usman (ML Engineer)
	â€¢	Hassan (QA Engineer)

â¸»

Sarah (PM):
â€œAlright team, quick round today. Letâ€™s sync on the AI Lead Scoring feature for our CRM. Ali, can you go first?â€

â¸»

Ali (Backend):
â€œSure. Yesterday, I completed the REST endpoint for /leads/score. It accepts the POST payload with lead ID, context object, and optional override flags. The service now asynchronously queues the request into Kafka â€” topic lead-score-requests â€” and expects the score from Usmanâ€™s scoring microservice via the lead-score-responses topic.â€

â€œThe async response is written back to our PostgreSQL lead_scores table, with columns: lead_id, score, confidence, explanation_json, and timestamp. Iâ€™m exposing a polling endpoint /leads/score/:id/status for the frontend to check processing state â€” itâ€™s currently stubbed but will return either PENDING, SUCCESS, or FAILED.â€

â€œToday, Iâ€™ll work on securing the endpoint with JWT scopes. Iâ€™ll use our existing middleware for crm.write.leads. ETA for prod-ready endpoint: 2 days.â€

â¸»

Sarah:
â€œGood. Letâ€™s make sure the explanation in explanation_json is human-readable. Tania?â€

â¸»

Tania (Frontend):
â€œIâ€™m working on the Lead Detail view in React. When the lead is scored, we show a badge: Hot, Warm, or Cold, based on the score threshold â€” above 80 is Hot, below 40 is Cold.â€

â€œWe also added a tooltip using react-tooltip that parses the explanation JSON. It includes rules like â€˜Visited pricing page 3+ timesâ€™, â€˜Opened email campaign Xâ€™, etc.â€

â€œIâ€™m building a horizontal bar chart with Recharts for visualizing scoring breakdown by feature importance. Usman, Iâ€™ll need the schema of explanation_json to map it properly.â€

â¸»

Usman (ML Engineer):
â€œSure, explanation JSON is structured as:

{
  'feature_importance': {
    'page_views': 0.45,
    'email_opens': 0.3,
    'demo_requested': 0.2,
    'form_filled': 0.05
  },
  'final_score': 88,
  'confidence': 0.92
}

â€œIâ€™m using XGBoost for now with SHAP values to generate the importance. Trained on 2 years of sales-labeled leads, using 23 features â€” behavioral and firmographic. Model is versioned via MLflow: model:v12. Itâ€™s hosted on FastAPI in a container on ECS.â€

â€œI deployed the endpoint /score-lead which accepts the full lead JSON. Response includes score, explanation, and confidence. Today, Iâ€™m adding an A/B toggle in the API for fallback model model:v11 just in case.â€

â¸»

Sarah:
â€œExcellent. Can we log the SHAP explanations in our feature store for retraining?â€

â¸»

Usman:
â€œYes. Iâ€™ll push each scoring instance to our lead_scoring_logs table in S3 via Glue job daily.â€

â¸»

Hassan (QA):
â€œIâ€™ve written Cypress tests for score badge rendering, tooltip validation, and polling behavior. Iâ€™ll test edge cases today â€” like malformed JSON in explanation, API timeouts, and fallback model switches.â€

â¸»

Sarah:
â€œPerfect. Letâ€™s align tomorrow on release readiness. We need this in staging by Friday EOD. Any blockers?â€

â¸»

Ali:
â€œNone from me.â€

â¸»

Tania:
â€œAll good, just need final CSS tweaks on the tooltip.â€

â¸»

Usman:
â€œIâ€™ll document the API schema on Confluence today.â€

â¸»

Hassan:
â€œIâ€™ll review that once itâ€™s up.â€

â¸»

Sarah:
â€œGreat. Thanks team. Letâ€™s sync tomorrow â€” same time.â€
